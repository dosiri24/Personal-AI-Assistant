"""
ìì—°ì–´ ì‘ë‹µ ìƒì„± ì‹œìŠ¤í…œ

AIê°€ ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì†Œí†µí•˜ê³  ì‘ì—… ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³´ê³ í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ì—¬ ê°œì¸í™”ëœ ì‘ë‹µì„ ìƒì„±í•˜ê³ , ì‘ì—… ê²°ê³¼ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.
"""

import asyncio
import json
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Union
from enum import Enum
from datetime import datetime

from ..utils.logger import get_logger
from .llm_provider import LLMProvider, ChatMessage
from .prompt_templates import PromptManager
from .decision_engine import Decision, DecisionContext


class ResponseType(Enum):
    """ì‘ë‹µ ìœ í˜•"""
    ACKNOWLEDGMENT = "acknowledgment"      # ëª…ë ¹ ìˆ˜ë½ í™•ì¸
    PROGRESS_UPDATE = "progress_update"    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
    CLARIFICATION = "clarification"        # ì¶”ê°€ ì •ë³´ ìš”ì²­
    SUCCESS_REPORT = "success_report"      # ì„±ê³µ ë³´ê³ 
    ERROR_REPORT = "error_report"          # ì˜¤ë¥˜ ë³´ê³ 
    GENERAL_RESPONSE = "general_response"  # ì¼ë°˜ ì‘ë‹µ


class ResponseTone(Enum):
    """ì‘ë‹µ í†¤"""
    PROFESSIONAL = "professional"    # ì „ë¬¸ì 
    FRIENDLY = "friendly"           # ì¹œê·¼í•œ
    CASUAL = "casual"               # ìºì£¼ì–¼í•œ
    FORMAL = "formal"               # ê²©ì‹ìˆëŠ”
    ENTHUSIASTIC = "enthusiastic"   # ì—´ì •ì ì¸


@dataclass
class ResponseContext:
    """ì‘ë‹µ ìƒì„± ì»¨í…ìŠ¤íŠ¸"""
    user_id: str
    user_message: str
    response_type: ResponseType
    decision: Optional[Decision] = None
    execution_result: Optional[Dict[str, Any]] = None
    error_info: Optional[Dict[str, Any]] = None
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    user_preferences: Dict[str, Any] = field(default_factory=dict)
    current_time: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "user_id": self.user_id,
            "user_message": self.user_message,
            "response_type": self.response_type.value,
            "decision": self.decision.to_dict() if self.decision else None,
            "execution_result": self.execution_result,
            "error_info": self.error_info,
            "conversation_history": self.conversation_history[-5:],  # ìµœê·¼ 5ê°œë§Œ
            "user_preferences": self.user_preferences,
            "current_time": self.current_time.isoformat()
        }


@dataclass
class ResponseOptions:
    """ì‘ë‹µ ìƒì„± ì˜µì…˜"""
    tone: ResponseTone = ResponseTone.FRIENDLY
    include_reasoning: bool = False
    include_next_steps: bool = True
    max_length: int = 500
    use_emojis: bool = True
    include_technical_details: bool = False


@dataclass
class GeneratedResponse:
    """ìƒì„±ëœ ì‘ë‹µ"""
    content: str
    response_type: ResponseType
    tone: ResponseTone
    estimated_reading_time: int  # ì´ˆ
    metadata: Optional[Dict[str, Any]] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """ì‘ë‹µì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "content": self.content,
            "response_type": self.response_type.value,
            "tone": self.tone.value,
            "estimated_reading_time": self.estimated_reading_time,
            "metadata": self.metadata or {}
        }


class ResponseGenerator:
    """
    ìì—°ì–´ ì‘ë‹µ ìƒì„±ê¸°
    
    ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ì—¬ ê°œì¸í™”ëœ ìì—°ì–´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì‘ì—… ì§„í–‰ ìƒí™©, ê²°ê³¼, ì˜¤ë¥˜ ë“±ì„ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, llm_provider: LLMProvider, prompt_manager: PromptManager):
        self.llm_provider = llm_provider
        self.prompt_manager = prompt_manager
        self.logger = get_logger("response_generator")
        
        # ì‚¬ìš©ìë³„ ê°œì¸í™” ì„¤ì • ì €ì¥
        self.user_preferences: Dict[str, Dict[str, Any]] = {}
        
        self.logger.info("ìì—°ì–´ ì‘ë‹µ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def generate_response(
        self, 
        context: ResponseContext, 
        options: Optional[ResponseOptions] = None
    ) -> GeneratedResponse:
        """
        ì»¨í…ìŠ¤íŠ¸ì— ë§ëŠ” ìì—°ì–´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤
        
        Args:
            context: ì‘ë‹µ ìƒì„± ì»¨í…ìŠ¤íŠ¸
            options: ì‘ë‹µ ìƒì„± ì˜µì…˜
            
        Returns:
            ìƒì„±ëœ ìì—°ì–´ ì‘ë‹µ
        """
        if options is None:
            options = ResponseOptions()
            
        try:
            self.logger.info(f"ì‘ë‹µ ìƒì„± ì‹œì‘: {context.response_type.value}")
            
            # ì‚¬ìš©ì ì„ í˜¸ë„ ì—…ë°ì´íŠ¸
            self._update_user_preferences(context.user_id, options)
            
            # ì‘ë‹µ íƒ€ì…ë³„ ì²˜ë¦¬
            if context.response_type == ResponseType.ACKNOWLEDGMENT:
                response = await self._generate_acknowledgment(context, options)
            elif context.response_type == ResponseType.PROGRESS_UPDATE:
                response = await self._generate_progress_update(context, options)
            elif context.response_type == ResponseType.CLARIFICATION:
                response = await self._generate_clarification(context, options)
            elif context.response_type == ResponseType.SUCCESS_REPORT:
                response = await self._generate_success_report(context, options)
            elif context.response_type == ResponseType.ERROR_REPORT:
                response = await self._generate_error_report(context, options)
            else:
                response = await self._generate_general_response(context, options)
            
            self.logger.info(f"ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response.content)}ì")
            return response
            
        except Exception as e:
            self.logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_fallback_response(context, options)
    
    async def _generate_acknowledgment(
        self, 
        context: ResponseContext, 
        options: ResponseOptions
    ) -> GeneratedResponse:
        """ëª…ë ¹ ìˆ˜ë½ í™•ì¸ ì‘ë‹µ ìƒì„±"""
        prompt = self._create_acknowledgment_prompt(context, options)
        
        messages = [ChatMessage(role="user", content=prompt)]
        response = await self.llm_provider.generate_response(messages)
        
        content = self._clean_response_content(response.content)
        reading_time = self._estimate_reading_time(content)
        
        return GeneratedResponse(
            content=content,
            response_type=ResponseType.ACKNOWLEDGMENT,
            tone=options.tone,
            estimated_reading_time=reading_time,
            metadata={
                "decision_confidence": context.decision.confidence_score if context.decision else None,
                "estimated_execution_time": context.decision.estimated_time if context.decision else None
            }
        )
    
    async def _generate_progress_update(
        self, 
        context: ResponseContext, 
        options: ResponseOptions
    ) -> GeneratedResponse:
        """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì‘ë‹µ ìƒì„±"""
        prompt = self._create_progress_prompt(context, options)
        
        messages = [ChatMessage(role="user", content=prompt)]
        response = await self.llm_provider.generate_response(messages)
        
        content = self._clean_response_content(response.content)
        reading_time = self._estimate_reading_time(content)
        
        return GeneratedResponse(
            content=content,
            response_type=ResponseType.PROGRESS_UPDATE,
            tone=options.tone,
            estimated_reading_time=reading_time,
            metadata={
                "execution_status": context.execution_result.get("status") if context.execution_result else None,
                "progress_percentage": context.execution_result.get("progress") if context.execution_result else None
            }
        )
    
    async def _generate_clarification(
        self, 
        context: ResponseContext, 
        options: ResponseOptions
    ) -> GeneratedResponse:
        """ì¶”ê°€ ì •ë³´ ìš”ì²­ ì‘ë‹µ ìƒì„±"""
        prompt = self._create_clarification_prompt(context, options)
        
        messages = [ChatMessage(role="user", content=prompt)]
        response = await self.llm_provider.generate_response(messages)
        
        content = self._clean_response_content(response.content)
        reading_time = self._estimate_reading_time(content)
        
        return GeneratedResponse(
            content=content,
            response_type=ResponseType.CLARIFICATION,
            tone=options.tone,
            estimated_reading_time=reading_time,
            metadata={
                "required_info": context.decision.user_input_prompt if context.decision else None,
                "confidence_score": context.decision.confidence_score if context.decision else None
            }
        )
    
    async def _generate_success_report(
        self, 
        context: ResponseContext, 
        options: ResponseOptions
    ) -> GeneratedResponse:
        """ì„±ê³µ ë³´ê³  ì‘ë‹µ ìƒì„±"""
        prompt = self._create_success_prompt(context, options)
        
        messages = [ChatMessage(role="user", content=prompt)]
        response = await self.llm_provider.generate_response(messages)
        
        content = self._clean_response_content(response.content)
        reading_time = self._estimate_reading_time(content)
        
        return GeneratedResponse(
            content=content,
            response_type=ResponseType.SUCCESS_REPORT,
            tone=options.tone,
            estimated_reading_time=reading_time,
            metadata={
                "execution_time": context.execution_result.get("execution_time") if context.execution_result else None,
                "tools_used": context.decision.selected_tools if context.decision else None
            }
        )
    
    async def _generate_error_report(
        self, 
        context: ResponseContext, 
        options: ResponseOptions
    ) -> GeneratedResponse:
        """ì˜¤ë¥˜ ë³´ê³  ì‘ë‹µ ìƒì„±"""
        prompt = self._create_error_prompt(context, options)
        
        messages = [ChatMessage(role="user", content=prompt)]
        response = await self.llm_provider.generate_response(messages)
        
        content = self._clean_response_content(response.content)
        reading_time = self._estimate_reading_time(content)
        
        return GeneratedResponse(
            content=content,
            response_type=ResponseType.ERROR_REPORT,
            tone=options.tone,
            estimated_reading_time=reading_time,
            metadata={
                "error_type": context.error_info.get("type") if context.error_info else None,
                "recovery_suggestion": context.error_info.get("suggestion") if context.error_info else None
            }
        )
    
    async def _generate_general_response(
        self, 
        context: ResponseContext, 
        options: ResponseOptions
    ) -> GeneratedResponse:
        """ì¼ë°˜ ì‘ë‹µ ìƒì„±"""
        prompt = self._create_general_prompt(context, options)
        
        messages = [ChatMessage(role="user", content=prompt)]
        response = await self.llm_provider.generate_response(messages)
        
        content = self._clean_response_content(response.content)
        reading_time = self._estimate_reading_time(content)
        
        return GeneratedResponse(
            content=content,
            response_type=ResponseType.GENERAL_RESPONSE,
            tone=options.tone,
            estimated_reading_time=reading_time
        )
    
    def _create_acknowledgment_prompt(self, context: ResponseContext, options: ResponseOptions) -> str:
        """ëª…ë ¹ ìˆ˜ë½ í™•ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        emoji_guide = "ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬" if options.use_emojis else "ì´ëª¨ì§€ ì—†ì´"
        tone_guide = self._get_tone_guide(options.tone)
        
        decision_info = ""
        if context.decision:
            decision_info = f"""
**AI ë¶„ì„ ê²°ê³¼:**
- ì„ íƒëœ ë„êµ¬: {', '.join(context.decision.selected_tools)}
- ì‹ ë¢°ë„: {context.decision.confidence_score:.2f}
- ì˜ˆìƒ ì†Œìš”ì‹œê°„: {context.decision.estimated_time}ì´ˆ
- ì‹¤í–‰ ê³„íš: {len(context.decision.execution_plan)}ë‹¨ê³„
"""
            if options.include_reasoning and context.decision.reasoning:
                decision_info += f"- AI ì¶”ë¡ : {context.decision.reasoning[:200]}..."
        
        return f"""ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ ëª…ë ¹ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤:
"{context.user_message}"

ë‹¹ì‹ ì€ ê°œì¸ AI ë¹„ì„œë¡œì„œ ì´ ëª…ë ¹ì„ ì²˜ë¦¬í•˜ê² ë‹¤ê³  í™•ì¸í•˜ëŠ” ì‘ë‹µì„ {tone_guide} {emoji_guide} ìƒì„±í•´ì£¼ì„¸ìš”.

{decision_info}

**ì‚¬ìš©ì ì •ë³´:**
- ì‚¬ìš©ì ID: {context.user_id}
- í˜„ì¬ ì‹œê°„: {context.current_time.strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}

**ì‘ë‹µ ìš”êµ¬ì‚¬í•­:**
- ê¸¸ì´: {options.max_length}ì ì´ë‚´
- í†¤: {tone_guide}
- ëª…ë ¹ì„ ì´í•´í–ˆìŒì„ í™•ì¸
- ì‘ì—… ì‹œì‘ì„ ì•Œë¦¼
{"- ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ í¬í•¨" if options.include_next_steps else ""}
{"- ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ í¬í•¨" if options.include_technical_details else "- ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ ì œì™¸"}

ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”."""
    
    def _create_progress_prompt(self, context: ResponseContext, options: ResponseOptions) -> str:
        """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        emoji_guide = "ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬" if options.use_emojis else "ì´ëª¨ì§€ ì—†ì´"
        tone_guide = self._get_tone_guide(options.tone)
        
        progress_info = ""
        if context.execution_result:
            progress_info = f"""
**í˜„ì¬ ì§„í–‰ ìƒí™©:**
- ìƒíƒœ: {context.execution_result.get('status', 'ì§„í–‰ ì¤‘')}
- ì§„í–‰ë¥ : {context.execution_result.get('progress', 0)}%
- í˜„ì¬ ë‹¨ê³„: {context.execution_result.get('current_step', 'N/A')}
- ì™„ë£Œëœ ì‘ì—…: {context.execution_result.get('completed_tasks', [])}
"""
        
        return f"""ì‚¬ìš©ìì˜ ëª…ë ¹ "{context.user_message}"ì„ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

{progress_info}

í˜„ì¬ ì§„í–‰ ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ {tone_guide} {emoji_guide} ì—…ë°ì´íŠ¸í•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì‘ë‹µ ìš”êµ¬ì‚¬í•­:**
- ê¸¸ì´: {options.max_length}ì ì´ë‚´
- í†¤: {tone_guide}
- í˜„ì¬ ì§„í–‰ ìƒí™© ëª…í™•íˆ ì „ë‹¬
- ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ì•ˆë‚´
{"- ë‹¤ìŒ ë‹¨ê³„ ë¯¸ë¦¬ë³´ê¸°" if options.include_next_steps else ""}

ì‚¬ìš©ìê°€ ì•ˆì‹¬í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  íˆ¬ëª…í•œ ì—…ë°ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
    
    def _create_clarification_prompt(self, context: ResponseContext, options: ResponseOptions) -> str:
        """ì¶”ê°€ ì •ë³´ ìš”ì²­ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        emoji_guide = "ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬" if options.use_emojis else "ì´ëª¨ì§€ ì—†ì´"
        tone_guide = self._get_tone_guide(options.tone)
        
        required_info = ""
        if context.decision and context.decision.user_input_prompt:
            required_info = f"í•„ìš”í•œ ì •ë³´: {context.decision.user_input_prompt}"
        
        return f"""ì‚¬ìš©ìê°€ "{context.user_message}"ë¼ê³  ìš”ì²­í–ˆì§€ë§Œ, ì‘ì—…ì„ ì™„ë£Œí•˜ê¸° ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.

{required_info}

ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì •ë³´ë¥¼ {tone_guide} {emoji_guide} ìš”ì²­í•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì‘ë‹µ ìš”êµ¬ì‚¬í•­:**
- ê¸¸ì´: {options.max_length}ì ì´ë‚´
- í†¤: {tone_guide}
- ì™œ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œì§€ ì„¤ëª…
- êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•œì§€ ëª…ì‹œ
- ì˜ˆì‹œë‚˜ ì˜µì…˜ ì œê³µ (ê°€ëŠ¥í•œ ê²½ìš°)

ì‚¬ìš©ìê°€ ì‰½ê²Œ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."""
    
    def _create_success_prompt(self, context: ResponseContext, options: ResponseOptions) -> str:
        """ì„±ê³µ ë³´ê³  í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        emoji_guide = "ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬" if options.use_emojis else "ì´ëª¨ì§€ ì—†ì´"
        tone_guide = self._get_tone_guide(options.tone)
        
        result_info = ""
        if context.execution_result:
            result_info = f"""
**ì‹¤í–‰ ê²°ê³¼:**
- ì™„ë£Œëœ ì‘ì—…: {context.execution_result.get('completed_tasks', [])}
- ì†Œìš” ì‹œê°„: {context.execution_result.get('execution_time', 'N/A')}ì´ˆ
- ì‚¬ìš©ëœ ë„êµ¬: {context.decision.selected_tools if context.decision else 'N/A'}
- ì¶”ê°€ ì •ë³´: {context.execution_result.get('additional_info', '')}
"""
        
        return f"""ì‚¬ìš©ìì˜ ëª…ë ¹ "{context.user_message}"ì„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!

{result_info}

ì„±ê³µ ì™„ë£Œë¥¼ {tone_guide} {emoji_guide} ë³´ê³ í•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì‘ë‹µ ìš”êµ¬ì‚¬í•­:**
- ê¸¸ì´: {options.max_length}ì ì´ë‚´
- í†¤: {tone_guide}
- ì™„ë£Œëœ ì‘ì—… ìš”ì•½
- ê²°ê³¼ë¬¼ì´ë‚˜ ë³€ê²½ì‚¬í•­ ì„¤ëª…
{"- ê´€ë ¨ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ" if options.include_next_steps else ""}

ì‚¬ìš©ìê°€ ë§Œì¡±í•  ìˆ˜ ìˆëŠ” ëª…í™•í•˜ê³  ê¸ì •ì ì¸ ì™„ë£Œ ë³´ê³ ë¥¼ í•´ì£¼ì„¸ìš”."""
    
    def _create_error_prompt(self, context: ResponseContext, options: ResponseOptions) -> str:
        """ì˜¤ë¥˜ ë³´ê³  í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        emoji_guide = "ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬" if options.use_emojis else "ì´ëª¨ì§€ ì—†ì´"
        tone_guide = self._get_tone_guide(options.tone)
        
        error_info = ""
        if context.error_info:
            error_info = f"""
**ì˜¤ë¥˜ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {context.error_info.get('type', 'Unknown')}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {context.error_info.get('message', 'N/A')}
- ë°œìƒ ë‹¨ê³„: {context.error_info.get('step', 'N/A')}
- í•´ê²° ë°©ë²•: {context.error_info.get('suggestion', 'ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”')}
"""
        
        return f"""ì‚¬ìš©ìì˜ ëª…ë ¹ "{context.user_message}"ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

{error_info}

ì˜¤ë¥˜ ìƒí™©ì„ {tone_guide} {emoji_guide} ë³´ê³ í•˜ê³  í•´ê²° ë°©ë²•ì„ ì œì•ˆí•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì‘ë‹µ ìš”êµ¬ì‚¬í•­:**
- ê¸¸ì´: {options.max_length}ì ì´ë‚´
- í†¤: {tone_guide}
- ë¬¸ì œ ìƒí™© ëª…í™•íˆ ì„¤ëª…
- ì‚¬ìš©ìê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ì¡°ì¹˜ ì•ˆë‚´
- ëŒ€ì•ˆì´ë‚˜ ìš°íšŒ ë°©ë²• ì œì‹œ (ê°€ëŠ¥í•œ ê²½ìš°)
- ì‚¬ê³¼ì™€ í•¨ê»˜ í•´ê²° ì˜ì§€ í‘œí˜„

ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê³  ë„ì›€ì´ ë˜ëŠ” ì˜¤ë¥˜ ë³´ê³ ë¥¼ í•´ì£¼ì„¸ìš”."""
    
    def _create_general_prompt(self, context: ResponseContext, options: ResponseOptions) -> str:
        """ì¼ë°˜ ì‘ë‹µ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        emoji_guide = "ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬" if options.use_emojis else "ì´ëª¨ì§€ ì—†ì´"
        tone_guide = self._get_tone_guide(options.tone)
        
        return f"""ì‚¬ìš©ìê°€ "{context.user_message}"ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤.

ê°œì¸ AI ë¹„ì„œë¡œì„œ ì´ì— ëŒ€í•œ {tone_guide} {emoji_guide} ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì •ë³´:**
- ì‚¬ìš©ì ID: {context.user_id}
- í˜„ì¬ ì‹œê°„: {context.current_time.strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}

**ì‘ë‹µ ìš”êµ¬ì‚¬í•­:**
- ê¸¸ì´: {options.max_length}ì ì´ë‚´
- í†¤: {tone_guide}
- ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³  ì ì ˆíˆ ì‘ë‹µ
- ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë‚˜ ì œì•ˆ í¬í•¨

ìì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”."""
    
    def _get_tone_guide(self, tone: ResponseTone) -> str:
        """í†¤ì— ë”°ë¥¸ ê°€ì´ë“œ í…ìŠ¤íŠ¸ ë°˜í™˜"""
        tone_guides = {
            ResponseTone.PROFESSIONAL: "ì „ë¬¸ì ì´ê³  ì •ì¤‘í•˜ê²Œ",
            ResponseTone.FRIENDLY: "ì¹œê·¼í•˜ê³  ë”°ëœ»í•˜ê²Œ", 
            ResponseTone.CASUAL: "í¸ì•ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ",
            ResponseTone.FORMAL: "ê²©ì‹ìˆê³  ì •ì¤‘í•˜ê²Œ",
            ResponseTone.ENTHUSIASTIC: "ì—´ì •ì ì´ê³  ê¸ì •ì ìœ¼ë¡œ"
        }
        return tone_guides.get(tone, "ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ë„ë¡")
    
    def _clean_response_content(self, content: str) -> str:
        """ì‘ë‹µ ë‚´ìš© ì •ë¦¬"""
        # ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ì œê±°
        content = content.replace("```", "").replace("**", "").strip()
        
        # ê¸¸ì´ ì œí•œ (Discord ë©”ì‹œì§€ ì œí•œ)
        if len(content) > 1900:
            content = content[:1900] + "..."
        
        return content
    
    def _estimate_reading_time(self, content: str) -> int:
        """ì½ê¸° ì‹œê°„ ì¶”ì • (ì´ˆ ë‹¨ìœ„)"""
        # í‰ê·  ì½ê¸° ì†ë„: ë¶„ë‹¹ 200ë‹¨ì–´ (í•œêµ­ì–´ëŠ” ê¸€ì ê¸°ì¤€)
        char_count = len(content)
        reading_time = max(1, char_count // 5)  # 5ê¸€ìë‹¹ 1ì´ˆ
        return min(reading_time, 60)  # ìµœëŒ€ 60ì´ˆ
    
    def _update_user_preferences(self, user_id: str, options: ResponseOptions):
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì—…ë°ì´íŠ¸"""
        if user_id not in self.user_preferences:
            self.user_preferences[user_id] = {}
        
        prefs = self.user_preferences[user_id]
        prefs.update({
            "preferred_tone": options.tone.value,
            "use_emojis": options.use_emojis,
            "include_technical_details": options.include_technical_details,
            "last_updated": datetime.now().isoformat()
        })
    
    def get_user_preferences(self, user_id: str) -> ResponseOptions:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ì‘ë‹µ ì˜µì…˜ ë°˜í™˜"""
        prefs = self.user_preferences.get(user_id, {})
        
        return ResponseOptions(
            tone=ResponseTone(prefs.get("preferred_tone", ResponseTone.FRIENDLY.value)),
            use_emojis=prefs.get("use_emojis", True),
            include_technical_details=prefs.get("include_technical_details", False)
        )
    
    def _create_fallback_response(self, context: ResponseContext, options: ResponseOptions) -> GeneratedResponse:
        """ì˜¤ë¥˜ ë°œìƒì‹œ ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
        fallback_messages = {
            ResponseType.ACKNOWLEDGMENT: "ëª…ë ¹ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤! ğŸš€",
            ResponseType.PROGRESS_UPDATE: "ì‘ì—…ì„ ê³„ì† ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤... â³",
            ResponseType.CLARIFICATION: "ì£„ì†¡í•©ë‹ˆë‹¤. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ì‹œ ìš”ì²­í•´ì£¼ì‹œê² ì–´ìš”? ğŸ¤”",
            ResponseType.SUCCESS_REPORT: "ì‘ì—…ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! âœ…",
            ResponseType.ERROR_REPORT: "ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. âŒ",
            ResponseType.GENERAL_RESPONSE: "ì•Œê² ìŠµë‹ˆë‹¤! ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š"
        }
        
        content = fallback_messages.get(context.response_type, "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return GeneratedResponse(
            content=content,
            response_type=context.response_type,
            tone=options.tone,
            estimated_reading_time=3
        )
