"""
í”„ë¡¬í”„íŠ¸ ìµœì í™” ê´€ë ¨ ëª…ë ¹ì–´ë“¤ (create-ab-test, analyze-ab-test, optimize-prompts)
"""

import asyncio
import click
from src.utils.logger import get_logger
from .utils import async_command, handle_errors


@click.command(name="create-ab-test")
@click.option("--test-name", default="response_quality_test", help="A/B í…ŒìŠ¤íŠ¸ ì´ë¦„")
@click.option("--duration", default=7, help="í…ŒìŠ¤íŠ¸ ê¸°ê°„ (ì¼)")
def create_ab_test(test_name, duration):
    """í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŠ¸ ìƒì„± ë° ì‹œì‘"""
    from src.ai_engine.prompt_optimizer import PromptOptimizer, PromptVariant, MetricType
    
    logger = get_logger("cli")
    
    try:
        click.echo("ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ìƒì„± ì¤‘...")
        
        optimizer = PromptOptimizer()
        
        # í…ŒìŠ¤íŠ¸ ë³€í˜• ìƒì„±
        variant_a = PromptVariant(
            id="variant_a_formal",
            name="formal_response",
            template="""ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•´ ê³µì‹ì ì´ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ì‚¬ìš©ì ìš”ì²­: $user_request

ì‘ë‹µì€ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”:
1. ìš”ì²­ ì´í•´ í™•ì¸
2. êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì‹œ
3. ì¶”ê°€ í•„ìš”ì‚¬í•­ ì•ˆë‚´

ì „ë¬¸ì ì´ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.""",
            description="ê³µì‹ì ì´ê³  ì „ë¬¸ì ì¸ í†¤ì˜ ì‘ë‹µ"
        )
        
        variant_b = PromptVariant(
            id="variant_b_casual",
            name="casual_response", 
            template="""ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•´ ì¹œê·¼í•˜ê³  ëŒ€í™”ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ì‚¬ìš©ì ìš”ì²­: $user_request

ì¹œêµ¬ì²˜ëŸ¼ í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•˜ë©´ì„œë„ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
ì´í•´í•˜ê¸° ì‰½ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.""",
            description="ì¹œê·¼í•˜ê³  ëŒ€í™”ì ì¸ í†¤ì˜ ì‘ë‹µ"
        )
        
        # A/B í…ŒìŠ¤íŠ¸ ìƒì„±
        test = optimizer.create_ab_test(
            name=test_name,
            description="ì‘ë‹µ í’ˆì§ˆê³¼ ì‚¬ìš©ì ë§Œì¡±ë„ ê°œì„ ì„ ìœ„í•œ í†¤ ë¹„êµ í…ŒìŠ¤íŠ¸",
            variants=[variant_a, variant_b],
            traffic_split={"variant_a_formal": 0.5, "variant_b_casual": 0.5},
            target_metrics=[MetricType.USER_SATISFACTION, MetricType.USER_ENGAGEMENT],
            min_sample_size=50
        )
        
        # í…ŒìŠ¤íŠ¸ ì‹œì‘
        success = optimizer.start_test(test.id)
        
        if success:
            click.echo(f"âœ… A/B í…ŒìŠ¤íŠ¸ ìƒì„± ë° ì‹œì‘ ì™„ë£Œ")
            click.echo(f"í…ŒìŠ¤íŠ¸ ID: {test.id}")
            click.echo(f"í…ŒìŠ¤íŠ¸ ì´ë¦„: {test.name}")
            click.echo(f"ë³€í˜• ìˆ˜: {len(test.variants)}")
            click.echo(f"ìµœì†Œ ìƒ˜í”Œ í¬ê¸°: {test.min_sample_size}")
            click.echo(f"ëŒ€ìƒ ì§€í‘œ: {[m.value for m in test.target_metrics]}")
        else:
            click.echo("âŒ A/B í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹¤íŒ¨")
            
    except Exception as e:
        logger.error(f"A/B í…ŒìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        click.echo(f"âŒ A/B í…ŒìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")


@click.command(name="analyze-ab-test")
@click.option("--test-id", help="ë¶„ì„í•  í…ŒìŠ¤íŠ¸ ID (ì—†ìœ¼ë©´ ëª¨ë“  í™œì„± í…ŒìŠ¤íŠ¸)")
def analyze_ab_test(test_id):
    """A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
    from src.ai_engine.prompt_optimizer import PromptOptimizer
    
    logger = get_logger("cli")
    
    try:
        click.echo("ğŸ“Š A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        
        optimizer = PromptOptimizer()
        
        if test_id:
            # íŠ¹ì • í…ŒìŠ¤íŠ¸ ë¶„ì„
            analysis = optimizer.analyze_test_results(test_id)
            
            if "error" in analysis:
                click.echo(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {analysis['error']}")
                return
                
            click.echo(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼: {analysis['test_name']}")
            click.echo(f"ìƒíƒœ: {analysis['status']}")
            click.echo(f"ì´ ìƒ˜í”Œ: {analysis['total_samples']}")
            
            # ë³€í˜•ë³„ ê²°ê³¼
            for variant_id, variant_data in analysis["variants"].items():
                click.echo(f"\nğŸ”¬ ë³€í˜•: {variant_data['name']}")
                click.echo(f"ìƒ˜í”Œ í¬ê¸°: {variant_data['sample_size']}")
                
                for metric, stats in variant_data["metrics"].items():
                    click.echo(f"  {metric}:")
                    click.echo(f"    í‰ê· : {stats['mean']:.3f}")
                    click.echo(f"    í‘œì¤€í¸ì°¨: {stats['std']:.3f}")
                    click.echo(f"    ë²”ìœ„: {stats['min']:.3f} - {stats['max']:.3f}")
            
            # í†µê³„ì  ìœ ì˜ì„±
            significance = analysis.get("statistical_significance", {})
            if significance:
                click.echo(f"\nğŸ“ˆ í†µê³„ì  ìœ ì˜ì„±:")
                for metric, data in significance.items():
                    if data.get("significant", False):
                        click.echo(f"  {metric}: âœ… ìœ ì˜ë¯¸ (ìŠ¹ì: {data['winner']})")
                        click.echo(f"    íš¨ê³¼ í¬ê¸°: {data['effect_size']:.1%}")
                    else:
                        click.echo(f"  {metric}: âŒ ìœ ì˜í•˜ì§€ ì•ŠìŒ")
            
            # ì¶”ì²œì‚¬í•­
            recommendations = analysis.get("recommendations", [])
            if recommendations:
                click.echo(f"\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
                for rec in recommendations:
                    click.echo(f"  - {rec}")
                    
        else:
            # ëª¨ë“  í™œì„± í…ŒìŠ¤íŠ¸ ë¶„ì„
            if not optimizer.active_tests:
                click.echo("í™œì„± A/B í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
                
            for test_id, test in optimizer.active_tests.items():
                click.echo(f"\nğŸ“Š í…ŒìŠ¤íŠ¸: {test.name} ({test_id})")
                analysis = optimizer.analyze_test_results(test_id)
                click.echo(f"ìƒ˜í”Œ ìˆ˜: {analysis.get('total_samples', 0)}")
                click.echo(f"ìƒíƒœ: {analysis.get('status', 'unknown')}")
                
        click.echo("\nâœ… A/B í…ŒìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"A/B í…ŒìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        click.echo(f"âŒ A/B í…ŒìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")


@click.command(name="optimize-prompts")
def optimize_prompts():
    """í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ìµœì í™” ì‹¤í–‰"""
    from src.config import get_settings
    from src.ai_engine.natural_language import NaturalLanguageProcessor
    
    logger = get_logger("cli")
    
    async def run_optimization():
        try:
            click.echo("âš¡ í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ìµœì í™” ì‹œì‘...")
            
            settings = get_settings()
            nlp = NaturalLanguageProcessor(settings)
            await nlp.initialize()
            
            # ìµœì í™” ì‹¤í–‰
            result = await nlp.optimize_prompt_performance()
            
            if result["status"] == "success":
                click.echo(f"âœ… ìµœì í™” ì™„ë£Œ")
                click.echo(f"ì ìš©ëœ ìµœì í™”: {result['optimizations_applied']}ê°œ")
                
                for test_id, analysis in result["results"].items():
                    click.echo(f"\nğŸ“Š {analysis.get('test_name', test_id)}:")
                    click.echo(f"  ìƒ˜í”Œ ìˆ˜: {analysis.get('total_samples', 0)}")
                    
                    significance = analysis.get("statistical_significance", {})
                    for metric, data in significance.items():
                        if data.get("significant", False):
                            click.echo(f"  âœ… {metric}: {data['winner']} ìŠ¹ë¦¬ ({data['effect_size']:.1%} ê°œì„ )")
                            
            else:
                click.echo(f"âŒ ìµœì í™” ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤íŒ¨: {e}", exc_info=True)
            click.echo(f"âŒ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    asyncio.run(run_optimization())


# ìµœì í™” ëª…ë ¹ì–´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ export
optimization_commands = [
    create_ab_test,
    analyze_ab_test,
    optimize_prompts
]
