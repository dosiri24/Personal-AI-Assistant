"""
Step 9.4: ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬í˜„
ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° ì‹œê°í™”
"""

import asyncio
import json
import threading
import time
import psutil
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import logging
from pathlib import Path

# ì™¸ë¶€ ëª¨ë“ˆ import
try:
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

try:
    import dash
    from dash import dcc, html, Input, Output, callback
    import dash_bootstrap_components as dbc
    DASH_AVAILABLE = True
except ImportError:
    DASH_AVAILABLE = False

from ..utils.logger import get_logger
from ..utils.error_handler import error_handler, AISystemError
from ..utils.performance import global_performance_monitor

logger = get_logger(__name__)

@dataclass
class SystemMetrics:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    memory_available_gb: float
    disk_usage_percent: float
    network_sent_mb: float
    network_recv_mb: float
    active_threads: int
    process_count: int
    load_average: Optional[float] = None

@dataclass
class AIMetrics:
    """AI ì—”ì§„ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: datetime
    total_requests: int
    successful_requests: int
    failed_requests: int
    average_response_time: float
    cache_hit_rate: float
    active_sessions: int
    queue_size: int
    model_temperature: float
    tokens_processed: int

@dataclass
class AlertRule:
    """ì•Œë¦¼ ê·œì¹™ ë°ì´í„° í´ë˜ìŠ¤"""
    name: str
    metric_type: str  # 'system' or 'ai'
    metric_name: str
    threshold: float
    operator: str  # '>', '<', '>=', '<=', '=='
    severity: str  # 'low', 'medium', 'high', 'critical'
    enabled: bool = True
    cooldown_minutes: int = 5

class MetricsCollector:
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, db_path: str = "data/monitoring.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(exist_ok=True)
        self._init_database()
        self._network_counters = None
        logger.info("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS system_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    cpu_percent REAL,
                    memory_percent REAL,
                    memory_available_gb REAL,
                    disk_usage_percent REAL,
                    network_sent_mb REAL,
                    network_recv_mb REAL,
                    active_threads INTEGER,
                    process_count INTEGER,
                    load_average REAL
                )
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS ai_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    total_requests INTEGER,
                    successful_requests INTEGER,
                    failed_requests INTEGER,
                    average_response_time REAL,
                    cache_hit_rate REAL,
                    active_sessions INTEGER,
                    queue_size INTEGER,
                    model_temperature REAL,
                    tokens_processed INTEGER
                )
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS alerts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    rule_name TEXT,
                    metric_type TEXT,
                    metric_name TEXT,
                    current_value REAL,
                    threshold REAL,
                    severity TEXT,
                    message TEXT,
                    resolved BOOLEAN DEFAULT FALSE
                )
            ''')
    
    @error_handler.handle_errors
    def collect_system_metrics(self) -> SystemMetrics:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            # ë©”ëª¨ë¦¬ ì •ë³´
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_available_gb = memory.available / (1024 ** 3)
            
            # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
            disk = psutil.disk_usage('/')
            disk_usage_percent = disk.percent
            
            # ë„¤íŠ¸ì›Œí¬ ì •ë³´
            network = psutil.net_io_counters()
            if self._network_counters:
                network_sent_mb = (network.bytes_sent - self._network_counters.bytes_sent) / (1024 ** 2)
                network_recv_mb = (network.bytes_recv - self._network_counters.bytes_recv) / (1024 ** 2)
            else:
                network_sent_mb = network_recv_mb = 0.0
            self._network_counters = network
            
            # í”„ë¡œì„¸ìŠ¤ ì •ë³´
            active_threads = threading.active_count()
            process_count = len(psutil.pids())
            
            # ë¡œë“œ í‰ê·  (ë¦¬ëˆ…ìŠ¤/ë§¥OSë§Œ)
            try:
                load_average = psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else None
            except:
                load_average = None
            
            return SystemMetrics(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                memory_available_gb=memory_available_gb,
                disk_usage_percent=disk_usage_percent,
                network_sent_mb=network_sent_mb,
                network_recv_mb=network_recv_mb,
                active_threads=active_threads,
                process_count=process_count,
                load_average=load_average
            )
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            raise AISystemError(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    @error_handler.handle_errors
    def collect_ai_metrics(self) -> AIMetrics:
        """AI ì—”ì§„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            monitor_stats = global_performance_monitor.get_statistics()
            
            # ìºì‹œ í†µê³„
            from ..utils.performance import global_cache
            cache_stats = global_cache.get_statistics()
            
            return AIMetrics(
                timestamp=datetime.now(),
                total_requests=monitor_stats.get('total_requests', 0),
                successful_requests=monitor_stats.get('successful_requests', 0),
                failed_requests=monitor_stats.get('failed_requests', 0),
                average_response_time=monitor_stats.get('avg_response_time', 0.0),
                cache_hit_rate=cache_stats.get('hit_rate', 0.0),
                active_sessions=monitor_stats.get('active_sessions', 0),
                queue_size=monitor_stats.get('queue_size', 0),
                model_temperature=0.7,  # ê¸°ë³¸ê°’
                tokens_processed=monitor_stats.get('tokens_processed', 0)
            )
        except Exception as e:
            logger.error(f"AI ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return AIMetrics(
                timestamp=datetime.now(),
                total_requests=0,
                successful_requests=0,
                failed_requests=0,
                average_response_time=0.0,
                cache_hit_rate=0.0,
                active_sessions=0,
                queue_size=0,
                model_temperature=0.7,
                tokens_processed=0
            )
    
    def save_metrics(self, system_metrics: SystemMetrics, ai_metrics: AIMetrics):
        """ë©”íŠ¸ë¦­ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        with sqlite3.connect(self.db_path) as conn:
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì €ì¥
            conn.execute('''
                INSERT INTO system_metrics 
                (cpu_percent, memory_percent, memory_available_gb, disk_usage_percent,
                 network_sent_mb, network_recv_mb, active_threads, process_count, load_average)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                system_metrics.cpu_percent,
                system_metrics.memory_percent,
                system_metrics.memory_available_gb,
                system_metrics.disk_usage_percent,
                system_metrics.network_sent_mb,
                system_metrics.network_recv_mb,
                system_metrics.active_threads,
                system_metrics.process_count,
                system_metrics.load_average
            ))
            
            # AI ë©”íŠ¸ë¦­ ì €ì¥
            conn.execute('''
                INSERT INTO ai_metrics 
                (total_requests, successful_requests, failed_requests, average_response_time,
                 cache_hit_rate, active_sessions, queue_size, model_temperature, tokens_processed)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                ai_metrics.total_requests,
                ai_metrics.successful_requests,
                ai_metrics.failed_requests,
                ai_metrics.average_response_time,
                ai_metrics.cache_hit_rate,
                ai_metrics.active_sessions,
                ai_metrics.queue_size,
                ai_metrics.model_temperature,
                ai_metrics.tokens_processed
            ))

class AlertSystem:
    """ì•Œë¦¼ ì‹œìŠ¤í…œ"""
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        self.alert_rules: List[AlertRule] = []
        self.last_alert_times: Dict[str, datetime] = {}
        self.alert_callbacks: List[Callable] = []
        logger.info("ì•Œë¦¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def add_alert_rule(self, rule: AlertRule):
        """ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        self.alert_rules.append(rule)
        logger.info(f"ì•Œë¦¼ ê·œì¹™ ì¶”ê°€: {rule.name}")
    
    def add_default_rules(self):
        """ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        default_rules = [
            AlertRule("ë†’ì€ CPU ì‚¬ìš©ë¥ ", "system", "cpu_percent", 80.0, ">", "high"),
            AlertRule("ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", "system", "memory_percent", 85.0, ">", "high"),
            AlertRule("ë‚®ì€ ë©”ëª¨ë¦¬ ê°€ìš©ëŸ‰", "system", "memory_available_gb", 1.0, "<", "medium"),
            AlertRule("ë†’ì€ ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ", "system", "disk_usage_percent", 90.0, ">", "critical"),
            AlertRule("ë†’ì€ ì‘ë‹µ ì‹œê°„", "ai", "average_response_time", 5.0, ">", "medium"),
            AlertRule("ë‚®ì€ ìºì‹œ íˆíŠ¸ìœ¨", "ai", "cache_hit_rate", 30.0, "<", "low"),
            AlertRule("ë§ì€ ì‹¤íŒ¨ ìš”ì²­", "ai", "failed_requests", 10, ">", "high"),
        ]
        
        for rule in default_rules:
            self.add_alert_rule(rule)
    
    def add_alert_callback(self, callback: Callable):
        """ì•Œë¦¼ ì½œë°± í•¨ìˆ˜ ì¶”ê°€"""
        self.alert_callbacks.append(callback)
    
    @error_handler.handle_errors
    def check_alerts(self, system_metrics: SystemMetrics, ai_metrics: AIMetrics):
        """ì•Œë¦¼ ê·œì¹™ í™•ì¸"""
        current_time = datetime.now()
        
        for rule in self.alert_rules:
            if not rule.enabled:
                continue
            
            # ì¿¨ë‹¤ìš´ í™•ì¸
            last_alert = self.last_alert_times.get(rule.name)
            if last_alert and (current_time - last_alert).total_seconds() < rule.cooldown_minutes * 60:
                continue
            
            # ë©”íŠ¸ë¦­ ê°’ ê°€ì ¸ì˜¤ê¸°
            if rule.metric_type == "system":
                current_value = getattr(system_metrics, rule.metric_name, None)
            elif rule.metric_type == "ai":
                current_value = getattr(ai_metrics, rule.metric_name, None)
            else:
                continue
            
            if current_value is None:
                continue
            
            # ì„ê³„ê°’ í™•ì¸
            triggered = False
            if rule.operator == ">":
                triggered = current_value > rule.threshold
            elif rule.operator == "<":
                triggered = current_value < rule.threshold
            elif rule.operator == ">=":
                triggered = current_value >= rule.threshold
            elif rule.operator == "<=":
                triggered = current_value <= rule.threshold
            elif rule.operator == "==":
                triggered = current_value == rule.threshold
            
            if triggered:
                self._trigger_alert(rule, current_value, current_time)
    
    def _trigger_alert(self, rule: AlertRule, current_value: float, timestamp: datetime):
        """ì•Œë¦¼ ë°œìƒ"""
        message = f"{rule.name}: {rule.metric_name} = {current_value} {rule.operator} {rule.threshold}"
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì•Œë¦¼ ì €ì¥
        with sqlite3.connect(self.metrics_collector.db_path) as conn:
            conn.execute('''
                INSERT INTO alerts 
                (rule_name, metric_type, metric_name, current_value, threshold, severity, message)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                rule.name,
                rule.metric_type,
                rule.metric_name,
                current_value,
                rule.threshold,
                rule.severity,
                message
            ))
        
        # ë§ˆì§€ë§‰ ì•Œë¦¼ ì‹œê°„ ì—…ë°ì´íŠ¸
        self.last_alert_times[rule.name] = timestamp
        
        # ì½œë°± í•¨ìˆ˜ í˜¸ì¶œ
        for callback in self.alert_callbacks:
            try:
                callback(rule, current_value, message)
            except Exception as e:
                logger.error(f"ì•Œë¦¼ ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        logger.warning(f"ğŸš¨ [{rule.severity.upper()}] {message}")

class ReportGenerator:
    """ë³´ê³ ì„œ ìƒì„±ê¸°"""
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        logger.info("ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    @error_handler.handle_errors
    def generate_system_report(self, hours: int = 24) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë³´ê³ ì„œ ìƒì„±"""
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        with sqlite3.connect(self.metrics_collector.db_path) as conn:
            cursor = conn.execute('''
                SELECT * FROM system_metrics 
                WHERE timestamp >= ? AND timestamp <= ?
                ORDER BY timestamp DESC
            ''', (start_time, end_time))
            
            rows = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
        
        if not rows:
            return {"error": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        # ë°ì´í„° ë¶„ì„
        metrics_data = [dict(zip(columns, row)) for row in rows]
        
        report = {
            "period": f"{start_time.strftime('%Y-%m-%d %H:%M')} ~ {end_time.strftime('%Y-%m-%d %H:%M')}",
            "total_records": len(metrics_data),
            "summary": {
                "cpu": {
                    "avg": sum(m['cpu_percent'] for m in metrics_data) / len(metrics_data),
                    "max": max(m['cpu_percent'] for m in metrics_data),
                    "min": min(m['cpu_percent'] for m in metrics_data)
                },
                "memory": {
                    "avg": sum(m['memory_percent'] for m in metrics_data) / len(metrics_data),
                    "max": max(m['memory_percent'] for m in metrics_data),
                    "min": min(m['memory_percent'] for m in metrics_data)
                },
                "disk": {
                    "avg": sum(m['disk_usage_percent'] for m in metrics_data) / len(metrics_data),
                    "max": max(m['disk_usage_percent'] for m in metrics_data),
                    "min": min(m['disk_usage_percent'] for m in metrics_data)
                }
            },
            "latest_metrics": metrics_data[0] if metrics_data else None
        }
        
        return report
    
    @error_handler.handle_errors
    def generate_ai_report(self, hours: int = 24) -> Dict[str, Any]:
        """AI ì—”ì§„ ë³´ê³ ì„œ ìƒì„±"""
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        with sqlite3.connect(self.metrics_collector.db_path) as conn:
            cursor = conn.execute('''
                SELECT * FROM ai_metrics 
                WHERE timestamp >= ? AND timestamp <= ?
                ORDER BY timestamp DESC
            ''', (start_time, end_time))
            
            rows = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
        
        if not rows:
            return {"error": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        # ë°ì´í„° ë¶„ì„
        metrics_data = [dict(zip(columns, row)) for row in rows]
        
        total_requests = metrics_data[0]['total_requests'] if metrics_data else 0
        successful_requests = metrics_data[0]['successful_requests'] if metrics_data else 0
        failed_requests = metrics_data[0]['failed_requests'] if metrics_data else 0
        
        success_rate = (successful_requests / total_requests * 100) if total_requests > 0 else 0
        
        report = {
            "period": f"{start_time.strftime('%Y-%m-%d %H:%M')} ~ {end_time.strftime('%Y-%m-%d %H:%M')}",
            "total_records": len(metrics_data),
            "summary": {
                "requests": {
                    "total": total_requests,
                    "successful": successful_requests,
                    "failed": failed_requests,
                    "success_rate": success_rate
                },
                "performance": {
                    "avg_response_time": sum(m['average_response_time'] for m in metrics_data) / len(metrics_data),
                    "cache_hit_rate": sum(m['cache_hit_rate'] for m in metrics_data) / len(metrics_data),
                    "tokens_processed": sum(m['tokens_processed'] for m in metrics_data)
                }
            },
            "latest_metrics": metrics_data[0] if metrics_data else None
        }
        
        return report

class MonitoringDashboard:
    """ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"""
    
    def __init__(self, port: int = 8050):
        self.port = port
        self.metrics_collector = MetricsCollector()
        self.alert_system = AlertSystem(self.metrics_collector)
        self.report_generator = ReportGenerator(self.metrics_collector)
        
        # ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì¶”ê°€
        self.alert_system.add_default_rules()
        
        # ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        self.monitoring_thread = None
        self.is_running = False
        
        # ì‹¤ì‹œê°„ ë°ì´í„° ì €ì¥
        self.real_time_data = {
            'system': deque(maxlen=100),
            'ai': deque(maxlen=100)
        }
        
        logger.info(f"ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì´ˆê¸°í™” ì™„ë£Œ (í¬íŠ¸: {port})")
    
    def start_monitoring(self, interval: int = 30):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.is_running:
            logger.warning("ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        self.is_running = True
        self.monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            args=(interval,),
            daemon=True
        )
        self.monitoring_thread.start()
        logger.info(f"ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ìˆ˜ì§‘ ê°„ê²©: {interval}ì´ˆ)")
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_running = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        logger.info("ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _monitoring_loop(self, interval: int):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.is_running:
            try:
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                system_metrics = self.metrics_collector.collect_system_metrics()
                ai_metrics = self.metrics_collector.collect_ai_metrics()
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                self.metrics_collector.save_metrics(system_metrics, ai_metrics)
                
                # ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸
                self.real_time_data['system'].append(asdict(system_metrics))
                self.real_time_data['ai'].append(asdict(ai_metrics))
                
                # ì•Œë¦¼ í™•ì¸
                self.alert_system.check_alerts(system_metrics, ai_metrics)
                
                time.sleep(interval)
                
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(interval)
    
    def get_dashboard_data(self) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë°˜í™˜"""
        return {
            'real_time_system': list(self.real_time_data['system'])[-20:],  # ìµœê·¼ 20ê°œ
            'real_time_ai': list(self.real_time_data['ai'])[-20:],
            'system_report': self.report_generator.generate_system_report(hours=1),
            'ai_report': self.report_generator.generate_ai_report(hours=1)
        }
    
    def create_dash_app(self):
        """Dash ì›¹ ì•± ìƒì„±"""
        if not DASH_AVAILABLE:
            logger.error("Dashê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install dash plotly ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
            return None
        
        app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
        
        app.layout = dbc.Container([
            dbc.Row([
                dbc.Col([
                    html.H1("ğŸ¤– Personal AI Assistant - ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ", className="text-center mb-4")
                ])
            ]),
            
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­", className="card-title"),
                            dcc.Graph(id="system-metrics-graph")
                        ])
                    ])
                ], width=6),
                
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("AI ì—”ì§„ ë©”íŠ¸ë¦­", className="card-title"),
                            dcc.Graph(id="ai-metrics-graph")
                        ])
                    ])
                ], width=6)
            ], className="mb-4"),
            
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ì‹œìŠ¤í…œ ìƒíƒœ", className="card-title"),
                            html.Div(id="system-status")
                        ])
                    ])
                ], width=6),
                
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ìµœê·¼ ì•Œë¦¼", className="card-title"),
                            html.Div(id="recent-alerts")
                        ])
                    ])
                ], width=6)
            ]),
            
            dcc.Interval(
                id='interval-component',
                interval=10*1000,  # 10ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
                n_intervals=0
            )
        ], fluid=True)
        
        @app.callback(
            [Output('system-metrics-graph', 'figure'),
             Output('ai-metrics-graph', 'figure'),
             Output('system-status', 'children'),
             Output('recent-alerts', 'children')],
            [Input('interval-component', 'n_intervals')]
        )
        def update_dashboard(n):
            return self._update_dashboard_callback()
        
        return app
    
    def _update_dashboard_callback(self):
        """ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸ ì½œë°±"""
        try:
            data = self.get_dashboard_data()
            
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ê·¸ë˜í”„
            system_fig = self._create_system_graph(data['real_time_system'])
            
            # AI ë©”íŠ¸ë¦­ ê·¸ë˜í”„
            ai_fig = self._create_ai_graph(data['real_time_ai'])
            
            # ì‹œìŠ¤í…œ ìƒíƒœ
            system_status = self._create_system_status(data['system_report'])
            
            # ìµœê·¼ ì•Œë¦¼
            recent_alerts = self._create_alerts_display()
            
            return system_fig, ai_fig, system_status, recent_alerts
            
        except Exception as e:
            logger.error(f"ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return {}, {}, f"ì˜¤ë¥˜: {e}", "ì•Œë¦¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    
    def _create_system_graph(self, data: List[Dict]):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ê·¸ë˜í”„ ìƒì„±"""
        if not data or not PLOTLY_AVAILABLE:
            return {}
        
        timestamps = [item['timestamp'] for item in data]
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('CPU ì‚¬ìš©ë¥ ', 'ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ', 'ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ', 'í™œì„± ìŠ¤ë ˆë“œ'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # CPU ì‚¬ìš©ë¥ 
        fig.add_trace(
            go.Scatter(x=timestamps, y=[item['cpu_percent'] for item in data],
                      mode='lines+markers', name='CPU %', line=dict(color='red')),
            row=1, col=1
        )
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        fig.add_trace(
            go.Scatter(x=timestamps, y=[item['memory_percent'] for item in data],
                      mode='lines+markers', name='Memory %', line=dict(color='blue')),
            row=1, col=2
        )
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
        fig.add_trace(
            go.Scatter(x=timestamps, y=[item['disk_usage_percent'] for item in data],
                      mode='lines+markers', name='Disk %', line=dict(color='green')),
            row=2, col=1
        )
        
        # í™œì„± ìŠ¤ë ˆë“œ
        fig.add_trace(
            go.Scatter(x=timestamps, y=[item['active_threads'] for item in data],
                      mode='lines+markers', name='Threads', line=dict(color='purple')),
            row=2, col=2
        )
        
        fig.update_layout(height=400, showlegend=False, title_text="ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­")
        return fig
    
    def _create_ai_graph(self, data: List[Dict]):
        """AI ë©”íŠ¸ë¦­ ê·¸ë˜í”„ ìƒì„±"""
        if not data or not PLOTLY_AVAILABLE:
            return {}
        
        timestamps = [item['timestamp'] for item in data]
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('ìš”ì²­ ìˆ˜', 'ì‘ë‹µ ì‹œê°„', 'ìºì‹œ íˆíŠ¸ìœ¨', 'í™œì„± ì„¸ì…˜'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # ì´ ìš”ì²­ ìˆ˜
        fig.add_trace(
            go.Scatter(x=timestamps, y=[item['total_requests'] for item in data],
                      mode='lines+markers', name='Total Requests', line=dict(color='orange')),
            row=1, col=1
        )
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„
        fig.add_trace(
            go.Scatter(x=timestamps, y=[item['average_response_time'] for item in data],
                      mode='lines+markers', name='Response Time', line=dict(color='red')),
            row=1, col=2
        )
        
        # ìºì‹œ íˆíŠ¸ìœ¨
        fig.add_trace(
            go.Scatter(x=timestamps, y=[item['cache_hit_rate'] for item in data],
                      mode='lines+markers', name='Cache Hit Rate', line=dict(color='green')),
            row=2, col=1
        )
        
        # í™œì„± ì„¸ì…˜
        fig.add_trace(
            go.Scatter(x=timestamps, y=[item['active_sessions'] for item in data],
                      mode='lines+markers', name='Active Sessions', line=dict(color='blue')),
            row=2, col=2
        )
        
        fig.update_layout(height=400, showlegend=False, title_text="AI ì—”ì§„ ë©”íŠ¸ë¦­")
        return fig
    
    def _create_system_status(self, report: Dict) -> html.Div:
        """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ ìƒì„±"""
        if 'error' in report:
            return html.Div([
                dbc.Alert("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", color="warning")
            ])
        
        latest = report.get('latest_metrics', {})
        if not latest:
            return html.Div([
                dbc.Alert("ìµœì‹  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤", color="info")
            ])
        
        cpu_color = "danger" if latest['cpu_percent'] > 80 else "warning" if latest['cpu_percent'] > 60 else "success"
        memory_color = "danger" if latest['memory_percent'] > 85 else "warning" if latest['memory_percent'] > 70 else "success"
        
        return html.Div([
            dbc.Row([
                dbc.Col([
                    dbc.Badge(f"CPU: {latest['cpu_percent']:.1f}%", color=cpu_color, className="me-2")
                ]),
                dbc.Col([
                    dbc.Badge(f"ë©”ëª¨ë¦¬: {latest['memory_percent']:.1f}%", color=memory_color, className="me-2")
                ])
            ]),
            html.Hr(),
            html.P([
                html.Strong("í™œì„± ìŠ¤ë ˆë“œ: "), f"{latest['active_threads']}ê°œ",
                html.Br(),
                html.Strong("í”„ë¡œì„¸ìŠ¤ ìˆ˜: "), f"{latest['process_count']}ê°œ",
                html.Br(),
                html.Strong("ê°€ìš© ë©”ëª¨ë¦¬: "), f"{latest['memory_available_gb']:.1f}GB"
            ])
        ])
    
    def _create_alerts_display(self) -> html.Div:
        """ìµœê·¼ ì•Œë¦¼ í‘œì‹œ ìƒì„±"""
        try:
            with sqlite3.connect(self.metrics_collector.db_path) as conn:
                cursor = conn.execute('''
                    SELECT timestamp, severity, message 
                    FROM alerts 
                    WHERE timestamp >= datetime('now', '-24 hours')
                    ORDER BY timestamp DESC 
                    LIMIT 5
                ''')
                alerts = cursor.fetchall()
            
            if not alerts:
                return html.Div([
                    dbc.Alert("ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ ì•Œë¦¼ì´ ì—†ìŠµë‹ˆë‹¤", color="success")
                ])
            
            alert_items = []
            for timestamp, severity, message in alerts:
                color = {
                    'low': 'info',
                    'medium': 'warning', 
                    'high': 'danger',
                    'critical': 'danger'
                }.get(severity, 'secondary')
                
                alert_items.append(
                    dbc.Alert([
                        html.Strong(f"[{severity.upper()}] "),
                        message,
                        html.Small(f" - {timestamp}", className="text-muted d-block")
                    ], color=color, className="py-2")
                )
            
            return html.Div(alert_items)
            
        except Exception as e:
            return html.Div([
                dbc.Alert(f"ì•Œë¦¼ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}", color="danger")
            ])
    
    def run_dashboard(self):
        """ëŒ€ì‹œë³´ë“œ ì‹¤í–‰"""
        app = self.create_dash_app()
        if app:
            logger.info(f"ëŒ€ì‹œë³´ë“œ ì„œë²„ ì‹œì‘: http://localhost:{self.port}")
            app.run_server(debug=False, host='0.0.0.0', port=self.port)
        else:
            logger.error("ëŒ€ì‹œë³´ë“œë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

# ì „ì—­ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì¸ìŠ¤í„´ìŠ¤
global_dashboard = MonitoringDashboard()

def start_monitoring():
    """ì „ì—­ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
    global_dashboard.start_monitoring()

def stop_monitoring():
    """ì „ì—­ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
    global_dashboard.stop_monitoring()

def get_monitoring_status() -> Dict[str, Any]:
    """ëª¨ë‹ˆí„°ë§ ìƒíƒœ ë°˜í™˜"""
    return {
        "is_running": global_dashboard.is_running,
        "dashboard_data": global_dashboard.get_dashboard_data()
    }

logger.info("ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
