"""Discord Bot AI ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ (ê°„ì†Œí™” ë²„ì „)

Discord Botê³¼ AI ì—”ì§„ ê°„ì˜ ë©”ì‹œì§€ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆ
"""

import asyncio
from datetime import datetime
from dataclasses import dataclass
from typing import Optional, List, Dict, Any
from loguru import logger

# AI ì—”ì§„ ê´€ë ¨ import
from ..ai_engine.llm_provider import GeminiProvider, ChatMessage
from ..config import Settings


@dataclass
class AIResponse:
    """AI ì‘ë‹µ ë°ì´í„° í´ë˜ìŠ¤"""
    content: str
    confidence: float = 1.0
    reasoning: str = "AI processing"
    needs_followup: bool = False
    tool_calls_made: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None
    
    def __post_init__(self):
        if self.tool_calls_made is None:
            self.tool_calls_made = []


class AIMessageHandler:
    """AI ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ - ê°„ì†Œí™”ëœ ë²„ì „"""
    
    def __init__(self, settings: Settings):
        self.settings = settings
        self.llm_provider: Optional[GeminiProvider] = None
        
        self._initialize_ai_engine()
        
    def _initialize_ai_engine(self):
        """AI ì—”ì§„ ì´ˆê¸°í™”"""
        try:
            if self.settings.has_valid_ai_api_key():
                self.llm_provider = GeminiProvider(self.settings)
                asyncio.create_task(self._async_initialize_gemini())
                logger.info("AI ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning("AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ. Mock ëª¨ë“œë¡œ ë™ì‘")
                self.llm_provider = None
        except Exception as e:
            logger.error(f"AI ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm_provider = None
    
    async def _async_initialize_gemini(self):
        """ë¹„ë™ê¸° Gemini ì´ˆê¸°í™”"""
        try:
            if self.llm_provider:
                success = await self.llm_provider.initialize()
                if success:
                    logger.info("Gemini Provider ë¹„ë™ê¸° ì´ˆê¸°í™” ì„±ê³µ")
                else:
                    logger.error("Gemini Provider ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨")
        except Exception as e:
            logger.error(f"Gemini Provider ë¹„ë™ê¸° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def process_message(self, user_message: str, user_id: str, channel_id: str) -> AIResponse:
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ AI ì—”ì§„ìœ¼ë¡œ ì²˜ë¦¬"""
        
        # 1ë‹¨ê³„: ë„êµ¬ í•„ìš”ì„± í™•ì¸ ë° ì‹¤í–‰
        tool_result = self._check_and_execute_tools(user_message)
        
        if not self.llm_provider:
            response_content = f"AI ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            if tool_result:
                response_content = f"{tool_result}\n\n{response_content}"
                
            return AIResponse(
                content=response_content,
                confidence=0.5,
                metadata={"error": "AI ì—”ì§„ ë¯¸ì´ˆê¸°í™”"}
            )
        
        # Geminiê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë‹¤ì‹œ ì‹œë„
        if not self.llm_provider.is_available():
            logger.info("Gemini Provider ì¬ì´ˆê¸°í™” ì‹œë„")
            try:
                success = await self.llm_provider.initialize()
                if not success:
                    logger.error("Gemini Provider ì¬ì´ˆê¸°í™” ì‹¤íŒ¨")
                    response_content = "AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    if tool_result:
                        response_content = f"{tool_result}\n\n{response_content}"
                    return AIResponse(
                        content=response_content,
                        confidence=0.0,
                        metadata={"error": "Gemini ì´ˆê¸°í™” ì‹¤íŒ¨"}
                    )
            except Exception as e:
                logger.error(f"Gemini Provider ì¬ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
                response_content = "AI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                if tool_result:
                    response_content = f"{tool_result}\n\n{response_content}"
                return AIResponse(
                    content=response_content,
                    confidence=0.0,
                    metadata={"error": str(e)}
                )
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            messages = self._build_prompt(user_message, user_id)
            
            # AI ì‘ë‹µ ìƒì„±
            ai_response = await self.llm_provider.generate_response(messages)
            
            # ë„êµ¬ ê²°ê³¼ì™€ AI ì‘ë‹µ í•©ì¹˜ê¸°
            enhanced_response = ai_response.content
            tools_used = []
            
            if tool_result:
                enhanced_response = f"{tool_result}\n\n{ai_response.content}"
                tools_used = ["tool_simulation"]
            
            return AIResponse(
                content=enhanced_response,
                confidence=0.9 if tools_used else 0.8,
                reasoning="AI ìì—°ì–´ ì²˜ë¦¬" + (" + ë„êµ¬ ì‹¤í–‰" if tools_used else ""),
                metadata={
                    "original_message": user_message,
                    "processed_at": datetime.now().isoformat(),
                    "model": "gemini-2.5-pro",
                    "tools_used": tools_used
                }
            )
            
        except Exception as e:
            logger.error(f"AI ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            response_content = "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            if tool_result:
                response_content = f"{tool_result}\n\n{response_content}"
            return AIResponse(
                content=response_content,
                confidence=0.0,
                metadata={"error": str(e)}
            )
    
    def _build_prompt(self, user_message: str, user_id: str) -> List[ChatMessage]:
        """AIë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        system_prompt = """ë‹¹ì‹ ì€ Discordì—ì„œ ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”.

ë©”ëª¨ë‚˜ í• ì¼ ê´€ë ¨ ìš”ì²­ì´ ìˆìœ¼ë©´ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì²˜ë¦¬í•œë‹¤ê³  ì•ˆë‚´í•˜ì„¸ìš”.
"""
        
        return [
            ChatMessage(role="system", content=system_prompt),
            ChatMessage(role="user", content=user_message)
        ]
    
    def _check_and_execute_tools(self, user_message: str) -> Optional[str]:
        """ê°„ë‹¨í•œ ë„êµ¬ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜"""
        message_lower = user_message.lower()
        
        # Notion ë©”ëª¨/í• ì¼ ê´€ë ¨
        if any(keyword in message_lower for keyword in ["ë©”ëª¨", "í• ì¼", "todo", "ê¸°ë¡", "ì €ì¥", "ì¶”ê°€", "ë‚¨ê²¨"]):
            memo_content = self._extract_memo_content(user_message)
            return f"âœ… [ì‹œë®¬ë ˆì´ì…˜] Notionì— ë©”ëª¨ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤: {memo_content}"
        
        # ê³„ì‚° ê´€ë ¨
        elif any(keyword in message_lower for keyword in ["ê³„ì‚°", "+", "-", "*", "/", "ë”í•˜ê¸°", "ë¹¼ê¸°"]):
            calculation = self._extract_calculation(user_message)
            try:
                import re
                if re.match(r'^[\d\+\-\*\/\(\)\.\s]+$', calculation):
                    result = eval(calculation)
                    return f"ğŸ”¢ ê³„ì‚° ê²°ê³¼: {calculation} = {result}"
                else:
                    return f"ğŸ”¢ [ì‹œë®¬ë ˆì´ì…˜] ê³„ì‚° ìš”ì²­: {calculation}"
            except:
                return f"ğŸ”¢ [ì‹œë®¬ë ˆì´ì…˜] ê³„ì‚° ìš”ì²­: {calculation}"
        
        # ì¸í•˜ëŒ€ ê³µì§€ì‚¬í•­ ê´€ë ¨
        elif any(keyword in message_lower for keyword in ["ì¸í•˜ëŒ€", "ê³µì§€ì‚¬í•­", "í¬ë¡¤ë§"]):
            return "ğŸ“° [ì‹œë®¬ë ˆì´ì…˜] ì¸í•˜ëŒ€ ê³µì§€ì‚¬í•­ì„ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤."
        
        # Echo ê´€ë ¨
        elif any(keyword in message_lower for keyword in ["echo", "ë°˜ë³µ", "ë”°ë¼í•´"]):
            return f"ğŸ”Š Echo: {user_message}"
        
        return None
    
    def _extract_memo_content(self, message: str) -> str:
        """ë©”ì‹œì§€ì—ì„œ ë©”ëª¨ ë‚´ìš© ì¶”ì¶œ"""
        if "ì‚¬ê³¼" in message:
            return "ì‚¬ê³¼ 4ê°œ êµ¬ë§¤"
        elif "ë©”ëª¨" in message:
            parts = message.split("ë©”ëª¨")
            if len(parts) > 1:
                content_part = parts[1]
                for word in ["ì—", "ë‚¨ê²¨", "ì¤˜", "ì¢€", "ë¼ê³ ", "í•˜ë¼ê³ "]:
                    content_part = content_part.replace(word, " ")
                content_part = content_part.strip()
                if content_part:
                    return content_part
        
        return message[:50] if len(message) > 50 else message
    
    def _extract_calculation(self, message: str) -> str:
        """ë©”ì‹œì§€ì—ì„œ ê³„ì‚°ì‹ ì¶”ì¶œ"""
        import re
        
        calc_pattern = r'(\d+(?:\.\d+)?)\s*([+\-*/])\s*(\d+(?:\.\d+)?)'
        match = re.search(calc_pattern, message)
        
        if match:
            return f"{match.group(1)}{match.group(2)}{match.group(3)}"
        
        if "ë”í•˜ê¸°" in message or "+" in message:
            numbers = re.findall(r'\d+(?:\.\d+)?', message)
            if len(numbers) >= 2:
                return f"{numbers[0]}+{numbers[1]}"
        
        return "1+1"
    
    def is_available(self) -> bool:
        """AI ì—”ì§„ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return self.llm_provider is not None
    
    async def get_status(self) -> Dict[str, Any]:
        """AI í•¸ë“¤ëŸ¬ ìƒíƒœ ì •ë³´"""
        status = {
            "ai_engine_available": self.is_available(),
            "api_key_configured": self.settings.has_valid_ai_api_key(),
            "model": "gemini-2.5-pro" if self.is_available() else "mock",
            "mode": "production" if self.is_available() else "mock"
        }
        
        if self.llm_provider:
            try:
                provider_available = self.llm_provider.is_available()
                status["llm_provider_available"] = provider_available
            except Exception as e:
                status["provider_error"] = str(e)
        
        return status


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_ai_handler: Optional[AIMessageHandler] = None

def get_ai_handler() -> AIMessageHandler:
    """ì „ì—­ AI í•¸ë“¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global _ai_handler
    if _ai_handler is None:
        logger.info("AI Handler ìƒˆë¡œ ìƒì„±")
        settings = Settings()
        _ai_handler = AIMessageHandler(settings)
        logger.info("AI Handler ì´ˆê¸°í™” ì™„ë£Œ")
    return _ai_handler

async def process_discord_message(
    user_message: str,
    user_id: int, 
    user_name: str,
    context: Optional[Dict[str, Any]] = None
) -> str:
    """
    Discord ë©”ì‹œì§€ë¥¼ AIë¡œ ì²˜ë¦¬í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Returns:
        AI ì‘ë‹µ ë¬¸ìì—´
    """
    handler = get_ai_handler()
    response = await handler.process_message(user_message, str(user_id), "general")
    return response.content
