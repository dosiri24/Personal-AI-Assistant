"""
ê¸°ì–µ ê´€ë¦¬ ì‹œìŠ¤í…œ (Memory Manager) - ë‹¨ìˆœí™” ë²„ì „

ì´ ëª¨ë“ˆì€ AI ì‹œìŠ¤í…œì˜ ì¥ê¸°ê¸°ì–µ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
ì£¼ìš” ê¸°ëŠ¥:
- ìë™ ì¤‘ìš”ë„ íŒë‹¨ ë° ì—…ë°ì´íŠ¸
- ê¸°ì–µ ì••ì¶• ë° ìš”ì•½
- ì˜¤ë˜ëœ ê¸°ì–µ ì•„ì¹´ì´ë¹™
- ê¸°ì–µ ì •ë¦¬ ë° ìµœì í™”

Author: Personal AI Assistant
Created: 2025-01-03
"""

from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
import asyncio
import statistics
from collections import defaultdict, Counter

from .enhanced_models import (
    BaseMemory, MetadataSchema, ImportanceLevel,
    MemoryType, MemoryStatus
)
from ..ai_engine.llm_provider import LLMProvider
from ..utils.logger import get_logger

logger = get_logger(__name__)


class ArchiveReason(Enum):
    """ì•„ì¹´ì´ë¹™ ì´ìœ """
    LOW_IMPORTANCE = "low_importance"
    OLD_AGE = "old_age"
    REDUNDANT = "redundant"
    USER_REQUEST = "user_request"
    STORAGE_LIMIT = "storage_limit"


class CompressionStrategy(Enum):
    """ì••ì¶• ì „ëµ"""
    SUMMARIZE = "summarize"  # LLMì„ ì‚¬ìš©í•œ ìš”ì•½
    EXTRACT_KEY_POINTS = "extract_key_points"  # í•µì‹¬ í¬ì¸íŠ¸ë§Œ ì¶”ì¶œ


@dataclass
class ArchiveEntry:
    """ì•„ì¹´ì´ë¸Œ ì—”íŠ¸ë¦¬"""
    memory_id: str
    original_memory: BaseMemory
    archive_date: datetime
    archive_reason: ArchiveReason
    compressed_content: Optional[str] = None
    compression_ratio: float = 1.0  # ì••ì¶• ë¹„ìœ¨ (0.0-1.0)


@dataclass
class MemoryStatistics:
    """ê¸°ì–µ í†µê³„"""
    total_memories: int = 0
    active_memories: int = 0
    archived_memories: int = 0
    average_importance: float = 0.0
    memory_by_type: Dict[MemoryType, int] = field(default_factory=dict)
    memory_by_importance: Dict[ImportanceLevel, int] = field(default_factory=dict)
    storage_usage_mb: float = 0.0
    oldest_memory_age_days: int = 0
    newest_memory_age_days: int = 0


class MemoryManager:
    """
    ê¸°ì–µ ê´€ë¦¬ ì‹œìŠ¤í…œ
    
    ê¸°ì–µì˜ ì „ì²´ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        llm_provider: LLMProvider,
        max_active_memories: int = 10000,
        archive_threshold_days: int = 365,
        low_importance_threshold: float = 0.3,
        compression_threshold_days: int = 30
    ):
        self.llm_provider = llm_provider
        
        # ì„¤ì •
        self.max_active_memories = max_active_memories
        self.archive_threshold_days = archive_threshold_days
        self.low_importance_threshold = low_importance_threshold
        self.compression_threshold_days = compression_threshold_days
        
        # ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ê°„ë‹¨í•œ ë”•ì…”ë„ˆë¦¬)
        self.memories: Dict[str, BaseMemory] = {}
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥ì†Œ
        self.archive: Dict[str, ArchiveEntry] = {}
        
        # í†µê³„
        self._last_statistics_update = datetime.now()
        self._cached_statistics: Optional[MemoryStatistics] = None
    
    async def initialize(self) -> None:
        """ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        logger.info("ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹œì‘")
        
        # ì´ˆê¸° í†µê³„ ê³„ì‚°
        await self.update_statistics()
        
        logger.info("ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def add_memory(self, memory: BaseMemory) -> str:
        """
        ìƒˆë¡œìš´ ê¸°ì–µ ì¶”ê°€
        
        Args:
            memory: ì¶”ê°€í•  ê¸°ì–µ
            
        Returns:
            memory_id: ìƒì„±ëœ ê¸°ì–µ ID
        """
        # ìë™ ì¤‘ìš”ë„ ê³„ì‚°
        if memory.metadata.importance_score == 0.0:
            memory.metadata.importance_score = await self._calculate_importance(memory)
            memory.metadata.importance_level = self._score_to_level(
                memory.metadata.importance_score
            )
        
        # ë©”ëª¨ë¦¬ ì €ì¥
        self.memories[memory.id] = memory
        
        # ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ ì²´í¬ ë° ì •ë¦¬
        await self._check_storage_limits()
        
        logger.info(f"ìƒˆë¡œìš´ ê¸°ì–µ ì¶”ê°€: {memory.id} (ì¤‘ìš”ë„: {memory.metadata.importance_score:.3f})")
        return memory.id
    
    async def update_memory_importance(self, memory_id: str) -> float:
        """
        ê¸°ì–µì˜ ì¤‘ìš”ë„ ì¬ê³„ì‚° ë° ì—…ë°ì´íŠ¸
        
        Args:
            memory_id: ì—…ë°ì´íŠ¸í•  ê¸°ì–µ ID
            
        Returns:
            new_importance_score: ìƒˆë¡œìš´ ì¤‘ìš”ë„ ì ìˆ˜
        """
        # ê¸°ì–µ ì¡°íšŒ
        memory = self.memories.get(memory_id)
        if not memory:
            raise ValueError(f"ê¸°ì–µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {memory_id}")
        
        # ì¤‘ìš”ë„ ì¬ê³„ì‚°
        new_score = await self._calculate_importance(memory)
        
        # ì—…ë°ì´íŠ¸
        memory.metadata.importance_score = new_score
        memory.metadata.importance_level = self._score_to_level(new_score)
        memory.metadata.last_accessed = datetime.now()
        
        logger.info(f"ê¸°ì–µ {memory_id} ì¤‘ìš”ë„ ì—…ë°ì´íŠ¸: {new_score:.3f}")
        return new_score
    
    async def compress_old_memories(
        self,
        strategy: CompressionStrategy = CompressionStrategy.SUMMARIZE,
        days_threshold: Optional[int] = None
    ) -> int:
        """
        ì˜¤ë˜ëœ ê¸°ì–µë“¤ì„ ì••ì¶•
        
        Args:
            strategy: ì••ì¶• ì „ëµ
            days_threshold: ì••ì¶• ëŒ€ìƒ ì¼ìˆ˜ ì„ê³„ê°’
            
        Returns:
            compressed_count: ì••ì¶•ëœ ê¸°ì–µ ìˆ˜
        """
        if days_threshold is None:
            days_threshold = self.compression_threshold_days
        
        cutoff_date = datetime.now() - timedelta(days=days_threshold)
        
        # ì••ì¶• ëŒ€ìƒ ê¸°ì–µë“¤ ì¡°íšŒ
        target_memories = [
            memory for memory in self.memories.values()
            if (memory.created_at < cutoff_date and 
                memory.metadata.status == MemoryStatus.ACTIVE and
                not memory.metadata.is_compressed)
        ]
        
        compressed_count = 0
        
        for memory in target_memories:
            try:
                compressed_content = await self._compress_memory_content(memory, strategy)
                if compressed_content:
                    # ì›ë³¸ ë‚´ìš©ì„ ì••ì¶•ëœ ë‚´ìš©ìœ¼ë¡œ ëŒ€ì²´
                    original_length = len(memory.content)
                    memory.content = compressed_content
                    memory.metadata.is_compressed = True
                    memory.metadata.compression_ratio = len(compressed_content) / original_length
                    memory.metadata.last_accessed = datetime.now()
                    
                    compressed_count += 1
                    
            except Exception as e:
                logger.error(f"ê¸°ì–µ {memory.id} ì••ì¶• ì‹¤íŒ¨: {e}")
        
        logger.info(f"ê¸°ì–µ ì••ì¶• ì™„ë£Œ: {compressed_count}ê°œ ì••ì¶•ë¨")
        return compressed_count
    
    async def archive_memories(
        self,
        criteria: Optional[Dict[str, Any]] = None
    ) -> int:
        """
        ê¸°ì–µë“¤ì„ ì•„ì¹´ì´ë¸Œë¡œ ì´ë™
        
        Args:
            criteria: ì•„ì¹´ì´ë¸Œ ê¸°ì¤€
            
        Returns:
            archived_count: ì•„ì¹´ì´ë¸Œëœ ê¸°ì–µ ìˆ˜
        """
        if criteria is None:
            criteria = {
                'max_age_days': self.archive_threshold_days,
                'min_importance': self.low_importance_threshold
            }
        
        # ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ ì„ ì •
        candidates = await self._find_archive_candidates(criteria)
        
        archived_count = 0
        
        for memory, reason in candidates:
            try:
                # ì••ì¶•ëœ ë²„ì „ ìƒì„±
                compressed_content = await self._create_compressed_summary(memory)
                
                # ì•„ì¹´ì´ë¸Œ ì—”íŠ¸ë¦¬ ìƒì„±
                archive_entry = ArchiveEntry(
                    memory_id=memory.id,
                    original_memory=memory,
                    archive_date=datetime.now(),
                    archive_reason=reason,
                    compressed_content=compressed_content,
                    compression_ratio=len(compressed_content) / len(memory.content) if compressed_content else 1.0
                )
                
                # ì•„ì¹´ì´ë¸Œì— ì¶”ê°€
                self.archive[memory.id] = archive_entry
                
                # ë©”ëª¨ë¦¬ì—ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸
                memory.metadata.status = MemoryStatus.ARCHIVED
                
                archived_count += 1
                
            except Exception as e:
                logger.error(f"ê¸°ì–µ {memory.id} ì•„ì¹´ì´ë¸Œ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ê¸°ì–µ ì•„ì¹´ì´ë¸Œ ì™„ë£Œ: {archived_count}ê°œ ì•„ì¹´ì´ë¸Œë¨")
        return archived_count
    
    async def get_memory_statistics(self, force_update: bool = False) -> MemoryStatistics:
        """
        ê¸°ì–µ í†µê³„ ì¡°íšŒ
        
        Args:
            force_update: ê°•ì œ ì—…ë°ì´íŠ¸ ì—¬ë¶€
            
        Returns:
            statistics: ê¸°ì–µ í†µê³„
        """
        # ìºì‹œëœ í†µê³„ê°€ ìˆê³  ìµœê·¼ ê²ƒì´ë©´ ë°˜í™˜
        if (not force_update and 
            self._cached_statistics and 
            (datetime.now() - self._last_statistics_update).seconds < 300):  # 5ë¶„ ìºì‹œ
            return self._cached_statistics
        
        await self.update_statistics()
        return self._cached_statistics or MemoryStatistics()
    
    async def update_statistics(self) -> None:
        """í†µê³„ ì •ë³´ ì—…ë°ì´íŠ¸"""
        logger.debug("ê¸°ì–µ í†µê³„ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        # ëª¨ë“  ê¸°ì–µ ì¡°íšŒ
        all_memories = list(self.memories.values())
        active_memories = [m for m in all_memories if m.metadata.status == MemoryStatus.ACTIVE]
        
        # ê¸°ë³¸ í†µê³„
        stats = MemoryStatistics()
        stats.total_memories = len(all_memories)
        stats.active_memories = len(active_memories)
        stats.archived_memories = len(self.archive)
        
        if active_memories:
            # ì¤‘ìš”ë„ í‰ê· 
            importance_scores = [m.metadata.importance_score for m in active_memories]
            stats.average_importance = statistics.mean(importance_scores)
            
            # íƒ€ì…ë³„ ë¶„í¬
            type_counter = Counter([m.memory_type for m in active_memories])
            stats.memory_by_type = dict(type_counter)
            
            # ì¤‘ìš”ë„ ë ˆë²¨ë³„ ë¶„í¬
            level_counter = Counter([m.importance for m in active_memories])
            stats.memory_by_importance = dict(level_counter)
            
            # ì €ì¥ ìš©ëŸ‰ ì¶”ì • (ë¬¸ì ìˆ˜ ê¸°ë°˜)
            total_chars = sum(len(m.content) for m in active_memories)
            stats.storage_usage_mb = total_chars * 2 / (1024 * 1024)  # UTF-8 ê¸°ì¤€ ê·¼ì‚¬ì¹˜
            
            # ì—°ë ¹ ì •ë³´
            now = datetime.now()
            ages = [(now - m.created_at).days for m in active_memories]
            stats.oldest_memory_age_days = max(ages) if ages else 0
            stats.newest_memory_age_days = min(ages) if ages else 0
        
        self._cached_statistics = stats
        self._last_statistics_update = datetime.now()
        
        logger.debug(f"í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: í™œì„± {stats.active_memories}ê°œ, ì•„ì¹´ì´ë¸Œ {stats.archived_memories}ê°œ")
    
    async def _calculate_importance(self, memory: BaseMemory) -> float:
        """
        ê¸°ì–µì˜ ì¤‘ìš”ë„ ìë™ ê³„ì‚°
        
        Args:
            memory: í‰ê°€í•  ê¸°ì–µ
            
        Returns:
            importance_score: ì¤‘ìš”ë„ ì ìˆ˜ (0.0-1.0)
        """
        factors = []
        
        # 1. ê¸°ë³¸ ì¤‘ìš”ë„ (ê¸°ì¡´ ì ìˆ˜ ì°¸ê³ )
        if memory.metadata.importance_score > 0:
            factors.append(('base', memory.metadata.importance_score, 0.3))
        
        # 2. ì ‘ê·¼ ë¹ˆë„
        access_factor = min(memory.metadata.access_count / 10.0, 1.0)
        factors.append(('access_frequency', access_factor, 0.2))
        
        # 3. ìµœê·¼ì„±
        days_since_created = (datetime.now() - memory.created_at).days
        recency_factor = max(0.0, 1.0 - (days_since_created / 365.0))
        factors.append(('recency', recency_factor, 0.2))
        
        # 4. ë‚´ìš© ë³µì¡ë„ (ê¸¸ì´ ê¸°ë°˜)
        content_length = len(memory.content)
        complexity_factor = min(content_length / 1000.0, 1.0)
        factors.append(('complexity', complexity_factor, 0.3))
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_sum = sum(score * weight for _, score, weight in factors)
        total_weight = sum(weight for _, _, weight in factors)
        
        final_score = weighted_sum / total_weight if total_weight > 0 else 0.0
        
        logger.debug(f"ì¤‘ìš”ë„ ê³„ì‚° ì™„ë£Œ: {final_score:.3f} (ìš”ì¸: {factors})")
        return min(max(final_score, 0.0), 1.0)  # 0.0-1.0 ë²”ìœ„ë¡œ ì œí•œ
    
    def _score_to_level(self, score: float) -> ImportanceLevel:
        """ì¤‘ìš”ë„ ì ìˆ˜ë¥¼ ë ˆë²¨ë¡œ ë³€í™˜"""
        if score >= 0.8:
            return ImportanceLevel.CRITICAL
        elif score >= 0.6:
            return ImportanceLevel.HIGH
        elif score >= 0.4:
            return ImportanceLevel.MEDIUM
        elif score >= 0.2:
            return ImportanceLevel.LOW
        elif score >= 0.1:
            return ImportanceLevel.MINIMAL
        else:
            return ImportanceLevel.TRIVIAL
    
    async def _compress_memory_content(
        self, 
        memory: BaseMemory,
        strategy: CompressionStrategy
    ) -> Optional[str]:
        """
        ê¸°ì–µ ë‚´ìš© ì••ì¶•
        
        Args:
            memory: ì••ì¶•í•  ê¸°ì–µ
            strategy: ì••ì¶• ì „ëµ
            
        Returns:
            compressed_content: ì••ì¶•ëœ ë‚´ìš© (ì‹¤íŒ¨ì‹œ None)
        """
        try:
            if strategy == CompressionStrategy.SUMMARIZE:
                # LLMì„ ì‚¬ìš©í•œ ìš”ì•½
                from ..ai_engine.llm_provider import ChatMessage
                
                messages = [
                    ChatMessage(
                        role="user",
                        content=f"""ë‹¤ìŒ ë‚´ìš©ì„ í•µì‹¬ ì •ë³´ë§Œ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ì›ë³¸ ë‚´ìš©:
{memory.content}

ìš”ì•½ ì¡°ê±´:
- ì›ë³¸ ê¸¸ì´ì˜ 30% ì´í•˜ë¡œ ì••ì¶•
- í•µì‹¬ ì •ë³´ì™€ ì¤‘ìš”í•œ ì„¸ë¶€ì‚¬í•­ ìœ ì§€
- ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
"""
                    )
                ]
                
                response = await self.llm_provider.generate_response(messages, max_tokens=300)
                return response.content.strip()
                
            elif strategy == CompressionStrategy.EXTRACT_KEY_POINTS:
                # í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ
                lines = memory.content.split('\n')
                key_lines = [line for line in lines if len(line.strip()) > 20][:5]  # ìƒìœ„ 5ê°œ ë¼ì¸
                return '\n'.join(key_lines)
                
            else:
                logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì••ì¶• ì „ëµ: {strategy}")
                return None
                
        except Exception as e:
            logger.error(f"ê¸°ì–µ ì••ì¶• ì‹¤íŒ¨: {e}")
            return None
    
    async def _find_archive_candidates(
        self, 
        criteria: Dict[str, Any]
    ) -> List[Tuple[BaseMemory, ArchiveReason]]:
        """
        ì•„ì¹´ì´ë¸Œ í›„ë³´ ê¸°ì–µë“¤ ì°¾ê¸°
        
        Args:
            criteria: ì•„ì¹´ì´ë¸Œ ê¸°ì¤€
            
        Returns:
            candidates: (ê¸°ì–µ, ì•„ì¹´ì´ë¸Œ ì´ìœ ) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        candidates = []
        
        # ëª¨ë“  í™œì„± ê¸°ì–µ ì¡°íšŒ
        active_memories = [
            m for m in self.memories.values() 
            if m.metadata.status == MemoryStatus.ACTIVE
        ]
        
        now = datetime.now()
        
        for memory in active_memories:
            reasons = []
            
            # ì—°ë ¹ ê¸°ì¤€
            age_days = (now - memory.created_at).days
            if age_days > criteria.get('max_age_days', self.archive_threshold_days):
                reasons.append(ArchiveReason.OLD_AGE)
            
            # ì¤‘ìš”ë„ ê¸°ì¤€
            if memory.metadata.importance_score < criteria.get('min_importance', self.low_importance_threshold):
                reasons.append(ArchiveReason.LOW_IMPORTANCE)
            
            # í›„ë³´ë¡œ ì„ ì •
            if reasons:
                # ì²« ë²ˆì§¸ ì´ìœ ë¥¼ ì£¼ìš” ì´ìœ ë¡œ ì‚¬ìš©
                candidates.append((memory, reasons[0]))
        
        return candidates
    
    async def _create_compressed_summary(self, memory: BaseMemory) -> str:
        """
        ê¸°ì–µì˜ ì••ì¶•ëœ ìš”ì•½ ìƒì„±
        
        Args:
            memory: ìš”ì•½í•  ê¸°ì–µ
            
        Returns:
            summary: ì••ì¶•ëœ ìš”ì•½
        """
        try:
            from ..ai_engine.llm_provider import ChatMessage
            
            messages = [
                ChatMessage(
                    role="user", 
                    content=f"""ë‹¤ìŒ ê¸°ì–µì„ í•œ ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{memory.content}

ì¡°ê±´:
- 50ë‹¨ì–´ ì´ë‚´
- ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë§Œ í¬í•¨
- ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ
"""
                )
            ]
            
            response = await self.llm_provider.generate_response(messages, max_tokens=100)
            return response.content.strip()
            
        except Exception as e:
            logger.error(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ìš”ì•½ ìƒì„±
            words = memory.content.split()[:20]
            return " ".join(words) + "..."
    
    async def _check_storage_limits(self) -> None:
        """ì €ì¥ì†Œ ìš©ëŸ‰ ì²´í¬ ë° í•„ìš”ì‹œ ì •ë¦¬"""
        active_count = len([m for m in self.memories.values() if m.metadata.status == MemoryStatus.ACTIVE])
        
        if active_count > self.max_active_memories:
            logger.warning(f"í™œì„± ê¸°ì–µ ìˆ˜ í•œê³„ ë„ë‹¬: {active_count}/{self.max_active_memories}")
            
            # ì˜¤ë˜ë˜ê³  ì¤‘ìš”ë„ê°€ ë‚®ì€ ê¸°ì–µë“¤ ìë™ ì•„ì¹´ì´ë¸Œ
            excess_count = active_count - self.max_active_memories
            await self._auto_archive_by_priority(excess_count)
    
    async def _auto_archive_by_priority(self, target_count: int) -> int:
        """
        ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ìë™ ì•„ì¹´ì´ë¸Œ
        
        Args:
            target_count: ëª©í‘œ ì•„ì¹´ì´ë¸Œ ìˆ˜
            
        Returns:
            archived_count: ì‹¤ì œ ì•„ì¹´ì´ë¸Œëœ ìˆ˜
        """
        # ëª¨ë“  í™œì„± ê¸°ì–µ ì¡°íšŒ
        active_memories = [
            m for m in self.memories.values() 
            if m.metadata.status == MemoryStatus.ACTIVE
        ]
        
        # ìš°ì„ ìˆœìœ„ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ë¨¼ì € ì•„ì¹´ì´ë¸Œ)
        priority_memories = []
        now = datetime.now()
        
        for memory in active_memories:
            age_days = (now - memory.created_at).days
            priority = (
                memory.metadata.importance_score * 0.5 +  # ì¤‘ìš”ë„ (ë†’ì„ìˆ˜ë¡ ë‚®ì€ ìš°ì„ ìˆœìœ„)
                (1.0 - min(age_days / 365.0, 1.0)) * 0.3 +  # ìµœê·¼ì„± (ë†’ì„ìˆ˜ë¡ ë‚®ì€ ìš°ì„ ìˆœìœ„)
                min(memory.metadata.access_count / 10.0, 1.0) * 0.2  # ì ‘ê·¼ ë¹ˆë„
            )
            priority_memories.append((priority, memory))
        
        # ìš°ì„ ìˆœìœ„ ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        priority_memories.sort(key=lambda x: x[0])
        
        # ìƒìœ„ target_count ê°œë¥¼ ì•„ì¹´ì´ë¸Œ
        archived_count = 0
        for priority, memory in priority_memories[:target_count]:
            try:
                archive_entry = ArchiveEntry(
                    memory_id=memory.id,
                    original_memory=memory,
                    archive_date=datetime.now(),
                    archive_reason=ArchiveReason.STORAGE_LIMIT,
                    compressed_content=await self._create_compressed_summary(memory)
                )
                
                self.archive[memory.id] = archive_entry
                memory.metadata.status = MemoryStatus.ARCHIVED
                
                archived_count += 1
                
            except Exception as e:
                logger.error(f"ìë™ ì•„ì¹´ì´ë¸Œ ì‹¤íŒ¨ {memory.id}: {e}")
        
        logger.info(f"ìš©ëŸ‰ ì œí•œìœ¼ë¡œ ìë™ ì•„ì¹´ì´ë¸Œ: {archived_count}ê°œ")
        return archived_count


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

async def create_memory_manager(
    llm_provider: LLMProvider,
    **kwargs
) -> MemoryManager:
    """ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì´ˆê¸°í™”"""
    manager = MemoryManager(
        llm_provider=llm_provider,
        **kwargs
    )
    await manager.initialize()
    return manager


def format_statistics(stats: MemoryStatistics) -> str:
    """í†µê³„ ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    return f"""
ğŸ“Š ê¸°ì–µ ì‹œìŠ¤í…œ í†µê³„

ì „ì²´ í˜„í™©:
  â€¢ ì´ ê¸°ì–µ ìˆ˜: {stats.total_memories:,}ê°œ
  â€¢ í™œì„± ê¸°ì–µ: {stats.active_memories:,}ê°œ
  â€¢ ì•„ì¹´ì´ë¸Œ: {stats.archived_memories:,}ê°œ
  â€¢ í‰ê·  ì¤‘ìš”ë„: {stats.average_importance:.3f}

ì €ì¥ í˜„í™©:
  â€¢ ì‚¬ìš©ëŸ‰: {stats.storage_usage_mb:.2f} MB
  â€¢ ê°€ì¥ ì˜¤ë˜ëœ ê¸°ì–µ: {stats.oldest_memory_age_days}ì¼ ì „
  â€¢ ê°€ì¥ ìµœê·¼ ê¸°ì–µ: {stats.newest_memory_age_days}ì¼ ì „

íƒ€ì…ë³„ ë¶„í¬:
{chr(10).join(f'  â€¢ {memory_type.value}: {count}ê°œ' for memory_type, count in stats.memory_by_type.items())}

ì¤‘ìš”ë„ë³„ ë¶„í¬:
{chr(10).join(f'  â€¢ {level.value}: {count}ê°œ' for level, count in stats.memory_by_importance.items())}
"""
